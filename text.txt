Введение
Развитие облачных технологий и концепции DevOps существенно изменило подход к проектированию и сопровождению корпоративных информационных систем. Для крупных организаций, обрабатывающих финансовые данные, особенно важны надёжность, безопасность и отказоустойчивость инфраструктуры. Современные инструменты контейнеризации позволяют достичь этих целей, обеспечивая изоляцию приложений, переносимость и предсказуемость работы в различных вычислительных средах.
Одним из наиболее распространённых инструментов контейнеризации является Docker, предоставляющий возможность создавать, упаковывать и развёртывать приложения в изолированных контейнерах. Использование Docker устраняет проблемы совместимости, ускоряет процесс внедрения обновлений и облегчает эксплуатацию систем. Для обеспечения непрерывной работы критически важных сервисов применяется оркестрация контейнеров с помощью Docker Swarm, которая позволяет объединять несколько узлов в единый кластер и автоматически управлять их состоянием.
Так как ручное обновление и развёртывание контейнеров требует значительных временных затрат и подвержено ошибкам, процесс доставки программного обеспечения автоматизируется с использованием CI/CD-конвейера на основе GitHub Actions. Это решение позволяет выполнять сборку, тестирование и деплой системы без участия пользователя, повышая стабильность и надёжность работы всей инфраструктуры.
Цель работы — разработать и развернуть отказоустойчивую облачную систему управления финансовыми данными на базе Docker-контейнеров, объединённых в кластер, с реализацией автоматизированного процесса поставки изменений.
Для достижения цели решаются следующие задачи:
1.	Провести анализ предметной области контейнерных технологий и существующих решений для управления корпоративными данными;
2.	Обосновать выбор технологического стека (Docker, Docker Swarm, PostgreSQL, FastAPI, GitHub Actions);
3.	Разработать архитектуру и состав контейнеров системы;
4.	Настроить кластерную инфраструктуру для обеспечения отказоустойчивости;
5.	Реализовать конвейер CI/CD для автоматизации развёртывания;
6.	Провести тестирование и документирование процесса настройки.
Объект исследования — методы и инструменты настройки и администрирования программного обеспечения с использованием технологий контейнеризации.
Предмет исследования — процесс развёртывания и эксплуатации облачной системы управления финансовыми данными, реализованной на базе Docker-контейнеров и оркестратора Docker Swarm.
Практическая значимость работы заключается в формировании подхода к построению надёжных облачных систем с применением современных DevOps-практик, что позволяет использовать разработанную инфраструктуру в корпоративных и учебных целях.





















Глава 1.

1.1. Анализ теоретической базы
В последние годы развитие облачных технологий и переход корпоративных систем на микросервисную архитектуру стали одним из ключевых направлений цифровой трансформации. Компании стремятся создавать приложения, способные масштабироваться, быстро обновляться и функционировать без простоев. Одним из фундаментальных инструментов, обеспечивающих реализацию этих требований, является технология контейнеризации. Она позволяет изолировать программные компоненты и их зависимости в единые исполняемые среды, которые можно легко переносить между различными серверами и облачными платформами.
Исторически контейнеризация развивалась как ответ на проблемы несовместимости программного обеспечения и различий в конфигурации окружений. Традиционная модель, когда приложение устанавливалось напрямую на операционную систему, приводила к многочисленным конфликтам библиотек и зависимостей. Появление контейнеров позволило стандартизировать процесс развёртывания: теперь разработчик может быть уверен, что приложение, работающее на его локальной машине, будет идентично функционировать и в производственной среде.
Наиболее распространённой платформой контейнеризации является Docker. Его популярность объясняется простотой использования, развитой экосистемой и возможностью автоматизировать процесс сборки и развертывания приложений. Использование Docker обеспечивает стабильность и предсказуемость работы, а также облегчает взаимодействие между командами разработчиков и системных администраторов. Следует отметить, что Docker стал не только инструментом, но и целой концепцией, которая объединила подходы DevOps в единую экосистему.
Для построения многокомпонентных систем, включающих несколько взаимосвязанных контейнеров, применяется Docker Compose. Он позволяет описывать конфигурацию сервисов, сетей и хранилищ в одном декларативном файле. Это делает возможным быстрое развертывание целого приложения одной командой и обеспечивает прозрачность инфраструктуры. В рамках учебных и исследовательских проектов Compose особенно удобен при создании локальной среды разработки, где необходимо согласованно запускать несколько сервисов — например, фронтенд, серверную часть и базу данных.
Однако по мере роста нагрузки и числа пользователей одной локальной конфигурации становится недостаточно. Для обеспечения высокой доступности и возможности горизонтального масштабирования используется оркестратор Docker Swarm. Он объединяет несколько узлов в единый кластер и управляет размещением контейнеров между ними. Если один из узлов выходит из строя, система автоматически перезапускает контейнеры на других машинах, тем самым обеспечивая отказоустойчивость. Кроме того, Docker Swarm позволяет безопасно хранить служебные данные, выполнять балансировку нагрузки и контролировать состояние сервисов. По сравнению с более сложными решениями вроде Kubernetes, Swarm отличается простотой настройки и быстрой интеграцией с Compose, что делает его рациональным выбором для проектов среднего масштаба.
Неотъемлемой частью любой корпоративной системы является база данных. Для хранения и обработки финансовой информации требуется надёжная, транзакционная и масштабируемая система управления. Этим требованиям в полной мере соответствует PostgreSQL — одна из наиболее зрелых и стабильных открытых СУБД. Она реализует все принципы ACID, обеспечивает высокую степень защиты данных и поддерживает сложные операции — включая транзакции, триггеры и хранимые процедуры. PostgreSQL хорошо масштабируется, поддерживает репликацию и активно развивается сообществом, что делает её устойчивым выбором для систем, в которых особенно важны целостность и достоверность данных.
Современные подходы к разработке программного обеспечения немыслимы без практик DevOps, сочетающих процессы разработки и эксплуатации в едином цикле. Одной из ключевых составляющих DevOps-культуры является непрерывная интеграция и доставка (CI/CD). Данная методология позволяет автоматически проверять, собирать и развёртывать приложение при каждом изменении исходного кода. Внедрение CI/CD-конвейера снижает риск ошибок, ускоряет выпуск обновлений и повышает стабильность релизов.
Среди множества инструментов автоматизации особое место занимает GitHub Actions, который обеспечивает тесную интеграцию с системой контроля версий GitHub. С его помощью можно настроить выполнение различных сценариев — от тестирования и сборки Docker-образов до их автоматического размещения в реестре и последующего развертывания на сервере. Для учебных и исследовательских проектов это решение особенно привлекательно, поскольку не требует выделенного оборудования и обеспечивает достаточную надёжность при минимальных затратах на администрирование.
Таким образом, сочетание технологий Docker, Docker Compose, Docker Swarm, PostgreSQL и GitHub Actions образует современный стек, позволяющий создавать гибкие, масштабируемые и отказоустойчивые системы. Эти инструменты образуют основу для построения облачной платформы управления финансовыми данными, соответствующей актуальным требованиям информационной безопасности и производительности.

1.2. Анализ конкурентных решений 
Для реализации облачной системы управления финансовыми данными был выбран технологический стек, обеспечивающий баланс между надёжностью, производительностью и простотой сопровождения. На этапе проектирования были проанализированы различные технологии и инструменты, обеспечивающие реализацию клиентской, серверной и инфраструктурной частей системы.
Выбор технологий для серверной части
В качестве основного языка программирования выбран Python, отличающийся лаконичным синтаксисом, широкой экосистемой библиотек и активным сообществом разработчиков. Для реализации серверной логики выбран фреймворк FastAPI, который сочетает простоту настройки с высокой производительностью за счёт асинхронного ввода-вывода.
FastAPI обеспечивает автоматическую генерацию документации OpenAPI, валидацию данных и совместимость с современными подходами REST API. Среди альтернатив рассматривались Flask и Django: первый требует ручной настройки большинства компонентов, а второй избыточен по функциональности для API-сервисов.
Для серверной логики были использованы следующие ключевые библиотеки Python:
•	SQLAlchemy – объектно-реляционный маппер (ORM), обеспечивающий взаимодействие с базой данных без написания SQL-запросов вручную;
•	Pydantic – библиотека валидации данных и сериализации объектов;
•	PyJWT – реализация стандарта JSON Web Token для безопасной аутентификации пользователей;
•	HTTPX – асинхронный HTTP-клиент, обеспечивающий взаимодействие с внешними сервисами;
•	ReportLab – библиотека для генерации PDF-документов, используемая для формирования финансовых отчётов.
Выбор данных инструментов обоснован их стабильностью, активной поддержкой сообществом и совместимостью с FastAPI.
Таблица 1 – Сравнение фреймворков для разработки серверной части
Фреймворк	Преимущества	Недостатки	Применимость
FastAPI	Высокая производительность, типизация, автоматическая документация	Требует базовых знаний асинхронного программирования	Оптимален для REST API
Flask	Минимализм, гибкость, простота освоения	Нет встроенной поддержки OpenAPI и валидации	Подходит для небольших API
Django	Полноценный фреймворк, ORM и админка «из коробки»	Избыточен для микросервисов	Для монолитных веб-приложений

Выбор технологий для клиентской части
Фронтенд-составляющая системы разработана на чистых HTML, CSS и JavaScript (Vanilla JS). Такой подход обеспечивает простоту развертывания, независимость от сборщиков и фреймворков, а также повышенную стабильность работы в изолированных корпоративных средах. Современные фреймворки, такие как React или Vue.js, обеспечивают гибкость и компонентность, но требуют дополнительной настройки инфраструктуры, что нецелесообразно для относительно простого пользовательского интерфейса внутренней системы.
Для обеспечения безопасности доступа к системе используется механизм аутентификации JWT (JSON Web Token) в связке с алгоритмом хеширования bcrypt.
Данный подход обеспечивает stateless-аутентификацию, при которой сервер не хранит информацию о сессиях пользователей. Это повышает масштабируемость и упрощает отказоустойчивое развертывание системы.
Выбор технологий для базы данных и инфраструктуры
Для хранения и обработки данных выбрана PostgreSQL. Эта СУБД гарантирует надёжность, целостность и поддержку транзакций, что особенно важно при работе с финансовыми данными. PostgreSQL реализует ACID-свойства и поддерживает параллельное выполнение запросов, триггеры, внешние ключи и хранимые процедуры. Среди альтернатив рассматривались MySQL и SQLite, но они уступают по уровню соответствия стандартам и масштабируемости.
В качестве платформы контейнеризации используется Docker, позволяющий упаковывать сервисы в независимые контейнеры. Для организации многоконтейнерной среды применяется Docker Compose, а для масштабируемости и отказоустойчивости — Docker Swarm. Оркестратор Swarm объединяет контейнеры в кластер, обеспечивая автоматическое восстановление и балансировку нагрузки.
CI/CD и DevOps-практики
Для автоматизации сборки и развертывания используется GitHub Actions. Данный инструмент обеспечивает тесную интеграцию с системой контроля версий GitHub, позволяет запускать сборки при каждом коммите и обеспечивает полный цикл CI/CD — от тестирования до деплоя.
Основными этапами конвейера CI/CD являются:
1.	Проверка синтаксиса и зависимостей Python-приложения.
2.	Сборка Docker-образов для frontend, backend и базы данных.
3.	Публикация образов в реестре Docker Hub.
4.	Развёртывание и тестирование контейнеров на целевой платформе.
Таблица 2 – Сравнение инструментов CI/CD
Интрументы	Преимущества	Недостатки	Особенности
GitHub Actions	Простая интеграция, бесплатные раннеры, облачная среда	Ограничения по времени выполнения	Оптимален для учебных и средних проектов
GitLab CI/CD	Поддержка Docker Runner, гибкая настройка	Требует собственной установки	Применяется в корпоративных системах
Jenkins	Расширяемость, множество плагинов	Требует выделенного сервера	Для крупных DevOps-инфраструктур

Вывод по первой главе
В ходе анализа предметной области были рассмотрены современные подходы к построению облачных и микросервисных систем, основанных на технологиях контейнеризации и оркестрации. Изучены принципы работы платформ Docker и Docker Swarm, обеспечивающих изоляцию, масштабируемость и отказоустойчивость приложений. Рассмотрены особенности применения систем управления базами данных для корпоративных решений, в частности использование PostgreSQL как надёжной и транзакционной СУБД, соответствующей требованиям хранения финансовой информации.
На основании проведённого анализа был сформирован оптимальный технологический стек для реализации облачной системы управления финансовыми данными. В него вошли: язык программирования Python и фреймворк FastAPI для построения серверной логики; HTML, CSS и JavaScript для создания пользовательского интерфейса; PostgreSQL для хранения данных; Docker, Docker Compose и Docker Swarm для контейнеризации и оркестрации; GitHub Actions для автоматизации процессов CI/CD; а также механизмы аутентификации JWT и шифрования bcrypt.
Выбранные инструменты обеспечивают модульность, переносимость и безопасность системы, а также соответствуют современным требованиям к корпоративным информационным платформам. Результаты анализа создают теоретическую основу для разработки архитектуры, настройки инфраструктуры и практической реализации проекта, которые рассматриваются во второй главе.









Глава 2.
2.1. Архитектура системы FinCloud
Современные корпоративные информационные системы, особенно те, которые работают с финансовыми данными, предъявляют повышенные требования к надёжности, безопасности и возможности масштабирования. В проекте FinCloud эти требования реализуются через микросервисную архитектуру и контейнеризацию: каждый компонент системы вынесен в отдельный сервис, запускается в собственном контейнере и взаимодействует с остальными через стандартные HTTP-API. Такой подход обеспечивает гибкость развития платформы, упрощает сопровождение и даёт возможность поэтапного расширения функционала.
Архитектура FinCloud включает четыре прикладных сервиса и один контейнер с СУБД PostgreSQL. В состав платформы входят: auth-service (аутентификация и управление пользователями), finance-service (логика учёта транзакций и балансов), report-service (генерация отчётов в PDF) и frontend-service (статические веб-страницы). СУБД PostgreSQL развёрнута в отдельном контейнере и используется всеми сервисами. При этом для большей организационной и логической раздельности данные для разных подсистем содержатся в отдельных базах/схемах внутри общего инстанса PostgreSQL — например, auth и finance используют отдельные логические схемы или базы в пределах одного сервера PostgreSQL.
Auth-Service отвечает за регистрацию, авторизацию пользователей и управление их учётными данными. Механизм аутентификации реализован на основе JWT: после успешной аутентификации сервис выдаёт токен, который используется для доступа к защищённым ресурсам. Пароли пользователей хранятся в виде хешей, полученных с помощью алгоритма bcrypt. Основные публичные эндпоинты сервиса включают /register, /login, /users и /health.
Finance-Service предоставляет функционал работы с транзакциями и балансами. Через эндпоинты /transactions, /balance и /health доступны операции записи новых транзакций, получения текущих балансов и проверки состояния сервиса. Для доступа к данным Finance-Service использует ORM (SQLAlchemy), а все критические операции выполняются в рамках транзакций PostgreSQL, что обеспечивает согласованность и целостность финансовой информации.
Report-Service реализует механизм формирования отчётов. На вход сервис получает параметры (период, фильтры) и по запросу /generate формирует PDF-документ с помощью библиотеки ReportLab; готовые отчёты доступны через /reports. Отчёты строятся на основе данных, сохранённых в PostgreSQL, и могут содержать табличные сведения и графические элементы, обеспечивая удобство дальнейшей аналитики и архивирования.
Frontend-Service реализован как набор статических HTML/CSS/JS страниц. Статические файлы обслуживаются отдельным контейнером с nginx; nginx в этой конфигурации выполняет роль веб-сервера для раздачи статических ресурсов. Взаимодействие клиентской части с backend-сервисами организовано через fetch-запросы к соответствующим REST-эндпоинтам. JWT-токен передаётся в заголовке Authorization при обращении к защищённым маршрутам, а во всех backend-сервисах настроена поддержка CORS для корректной обработки cross-origin-запросов от фронтенда.
Все backend-сервисы и база данных объединены в внутреннюю сеть Docker, что упрощает коммуникацию и повышает безопасность: доступ к PostgreSQL ограничен внутренним пространством сети и недоступен напрямую извне. Такой дизайн позволяет минимизировать «публичную поверхность атаки» и централизовать политику доступа к данным. Кроме того, разделение логики по сервисам даёт возможность отдельного масштабирования и обновления — например, при росте нагрузки на отчётность можно увеличить ресурсы только для report-service.
Контейнеризация реализована с помощью Docker: для каждого сервиса имеется собственный Dockerfile, а локальная разработка и тестирование организованы через docker-compose.yml. Для имитации production-окружения и демонстрации оркестрации подготовлена отдельная конфигурация docker-compose.swarm-simple.yml, использующая возможности Docker Swarm. Инициализация кластера выполняется в простом режиме manager/worker, без сложного распределённого хранения и автоматического рескейлинга; цель такого решения — показать подход к развёртыванию в кластере и обеспечить базовую отказоустойчивость на уровне реплик сервисов.
Важным элементом проекта является полноценный конвейер CI/CD, реализованный на базе GitHub Actions. При обновлении репозитория автоматически запускается процесс проверки и доставки кода: производится анализ и тестирование компонентов системы, формируются контейнерные образы сервисов и выполняется их развёртывание в рабочую среду.
Инфраструктура развернута в Docker Swarm, что обеспечивает централизованное управление сервисами, обновление без остановки работы системы и контроль их состояния после публикации изменений. Такой подход соответствует современным практикам DevOps и позволяет поддерживать стабильность и актуальность платформы при минимальном участии разработчика, обеспечивая непрерывность разработки и доставки программного обеспечения.

 
Рисунок 1 – Архитектура FinCloud

2.2. Функциональные возможности системы и реализация серверной логики
Разрабатываемая система FinCloud представляет собой облачную платформу для управления финансовыми данными. Её функциональность организована в соответствии с принципами микросервисной архитектуры, что позволяет разделить обязанности между независимыми компонентами и обеспечить масштабируемость решения.
Основная роль backend-части заключается в обработке пользовательских запросов, выполнении бизнес-логики, обеспечении безопасного хранения данных и формировании отчётности. Для этого разработаны три самостоятельных сервиса: сервис аутентификации, сервис финансового учёта и сервис формирования отчётов.
Сервис аутентификации отвечает за регистрацию пользователей, их авторизацию и управление учётными записями. При обращении клиента выполняется проверка переданных данных, хеширование паролей алгоритмом bcrypt и создание JWT-токенов, которые используются для подтверждения личности при последующих запросах. Такой подход освобождает систему от необходимости хранения серверных сессий и обеспечивает независимость сервисов при масштабировании.
Сервис финансовых операций реализует работу с пользовательскими транзакциями и расчёт текущего баланса. Он предоставляет API-эндпоинты для создания, получения и анализа финансовых записей. Логика системы предусматривает валидацию данных, контроль авторизованного доступа и работу с отдельной схемой базы данных, что гарантирует корректность финансовой информации и её изоляцию от других доменов данных.
Сервис отчётов обеспечивает формирование финансовых документов в формате PDF. Для подготовки отчётов он запрашивает актуальные данные у финансового сервиса, обрабатывает их в соответствии с параметрами запроса и использует библиотеку ReportLab для генерации итогового файла. Такой подход позволяет пользователю получать готовую отчётность непосредственно через веб-интерфейс, без необходимости работы с внешними программами.
Взаимодействие между клиентской частью и серверами осуществляется через REST API с использованием HTTP-методов и JSON-формата обмена данными. Фронтенд отправляет запросы к нужным сервисам, добавляя JWT-токены в заголовки для авторизации. Обработка ошибок и валидация данных реализованы на стороне backend-сервисов, что повышает устойчивость системы к некорректным запросам и обеспечивает единый стандарт работы API.
Таким образом, архитектура backend-части обеспечивает выполнение всех ключевых задач платформы: аутентификацию пользователей, управление финансовой информацией и подготовку отчётов. Разделение логики между независимыми сервисами повышает гибкость системы и создаёт основу для дальнейшего расширения функциональности.

2.3. Контейнеризация сервисов
Контейнеризация является ключевым технологическим решением при реализации системы FinCloud, обеспечивая изоляцию компонентов, предсказуемость среды и удобство развертывания. Каждый сервис работает в собственном Docker-контейнере, внутри которого находятся необходимые зависимости, интерпретатор, библиотеки и исполняемый код. Такой подход позволяет избежать конфликтов между версиями компонентов, упростить управление окружением и быстрее разворачивать систему в любом поддерживаемом инфраструктурном окружении.
Для каждого микросервиса — аутентификации, финансового учёта, формирования отчётности, а также для клиентской части — разработаны отдельные Dockerfile-файлы. Они определяют инструкции для создания контейнерного образа: базовый образ, установку зависимостей, копирование исходного кода, выполнение тестов, а также команды запуска приложения. В backend-сервисах используется Python и фреймворк FastAPI, поэтому образы формируются на основе официальных Python-контейнеров. Frontend-часть разворачивается в контейнере nginx и обслуживает статические веб-страницы, реализующие интерфейс пользователя.
Также в инфраструктуру включён контейнер с PostgreSQL, выступающий в роли централизованной системы хранения данных. Он использует постоянный Docker-volume, обеспечивая сохранность информации вне зависимости от состояния контейнера и исключая её потерю при обновлении или перезапуске сервисов.
Организация контейнеров описана в файле docker-compose.yml, упрощающем локальное развёртывание проекта. В нём определены сервисы, сетевые настройки, переменные окружения, тома для хранения данных, а также зависимости между компонентами. Благодаря docker-compose разработчик может запускать всю систему одной командой и поддерживать единообразную конфигурацию окружения. Для развертывания в кластер Docker Swarm используется отдельный конфигурационный файл, адаптированный под отказоустойчивую архитектуру.
Построенная таким образом модель контейнеризации обеспечивает гибкость и масштабируемость решения, а также создаёт основу для дальнейшего применения технологий оркестрации и автоматизированного развёртывания. Она упрощает эксплуатацию системы, повышает воспроизводимость результатов и минимизирует различия между средами разработки, тестирования и эксплуатации.

2.4. Оркестрация контейнеров с использованием Docker Swarm
Для управления контейнерами и обеспечения устойчивого функционирования системы FinCloud используется технология оркестрации Docker Swarm. Она позволяет объединить серверные ресурсы в единый кластер, автоматизировать запуск сервисов, контролировать их состояние и поддерживать доступность приложения при обновлениях или возможных сбоях отдельных контейнеров.
Docker Swarm обеспечивает распределение контейнеров по доступным узлам кластера и управление их жизненным циклом на основе заранее определённой конфигурации. В частности, система автоматически следит за тем, чтобы каждый сервис находился в рабочем состоянии, и при необходимости перезапускает контейнеры, восстанавливая корректное состояние приложения без вмешательства пользователя. Такой механизм повышает отказоустойчивость и позволяет поддерживать непрерывность работы системы.
Развёртывание в Docker Swarm выполняется на основе конфигурации, описанной в отдельном файле, где заданы параметры сервисов, сетевые настройки, тома и переменные среды. В отличие от классического Docker Compose, Swarm предоставляет возможность задавать количество реплик сервисов, использовать встроенные механизмы балансировки нагрузки и изолировать компоненты в пределах распределённых overlay-сетей. Каждый сервис FinCloud получает доступ только к тем ресурсам, которые необходимы для его функционирования, что повышает уровень безопасности и управляемости архитектуры.
Для backend-сервисов настроены проверки готовности (health-check), позволяющие оркестратору отслеживать доступность компонентов и своевременно принимать меры при отклонениях в их работе. Обновление сервисов выполняется пошагово, что предотвращает простои и обеспечивает плавный переход на новую версию программного обеспечения. В сочетании с механизмами контейнеризации Docker Swarm создаёт гибкую и масштабируемую среду, упрощающую эксплуатацию системы и повышающую её надёжность.
Использование оркестратора в проекте демонстрирует применимость современных подходов в области построения распределённых приложений, позволяющих объединять несколько микросервисов в единую управляемую платформу, сохраняя при этом модульность, отказоустойчивость и возможность дальнейшего масштабирования.



2.5. Автоматизация разработки и развертывания средствами CI/CD
Для обеспечения непрерывной разработки и поддержания стабильности программного продукта в проекте реализован конвейер CI/CD на базе GitHub Actions. Данный механизм автоматизирует процессы проверки, сборки и доставки кода, позволяя оперативно разворачивать обновления и минимизируя вероятность ошибок, связанных с ручным вмешательством.
CI/CD-процесс активируется автоматически при внесении изменений в репозиторий. После получения обновлений выполняются процедуры анализа кода, тестирование отдельных модулей и проверка корректности взаимодействия сервисов. Такой подход обеспечивает раннее выявление возможных ошибок и гарантирует, что весь функционал системы остаётся работоспособным после внесения новых изменений.
После успешного завершения проверки система инициирует сборку контейнерных образов всех сервисов и подготовку их к развёртыванию. Благодаря этому обеспечивается единообразие окружения, предсказуемость поведения приложений и возможность разворачивания системы на любом поддерживаемом сервере. Сформированные образы применяются к кластеру Docker Swarm, обновляя работающие экземпляры сервисов без прерывания их работы. Оркестратор контролирует состояние компонентов и автоматически переключает нагрузку, обеспечивая плавное внедрение изменений.
Использование GitHub Actions позволяет централизованно управлять процессами разработки, документировать результаты выполнения каждого этапа и сохранять историю всех прошедших сборок. Таким образом, достигается высокая степень прозрачности и контролируемости жизненного цикла программного обеспечения. Применение CI/CD-подхода делает систему устойчивой к человеческому фактору, сокращает время вывода изменений в эксплуатацию и обеспечивает динамическое развитие проекта в соответствии с современными практиками DevOps
